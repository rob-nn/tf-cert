{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd3d89df-d9c3-4d3a-ae24-de716782e7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "url = \"https://storage.googleapis.com/learning-datasets/horse-or-human.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5e9535-3b29-4edc-b78a-b7a0ecfb3497",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('horse-or-human.zip', <http.client.HTTPMessage at 0x7f8041ed3610>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"horse-or-human.zip\"\n",
    "training_dir = 'horse-or-human/training'\n",
    "urllib.request.urlretrieve(url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb11263-75da-42e8-8b6b-c08ca4d1d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
    "zip_ref.extractall(training_dir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c1881c-9a2b-47c6-9b8a-335b4712a413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch03.1.ipynb\t\t horse-human-model.h5  validation-horse-or-human.zip\n",
      "ch03.2-validation.ipynb  horse-or-human\n",
      "ch03.2.ipynb\t\t horse-or-human.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9f082c-82ef-44f5-bb13-663c15d27d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 02:50:16.928996: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd2f411-4a8d-4810-a721-64cf6d9ddb5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2007a04-6748-4378-bdcc-d9c4e2ac4528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1029 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(300,300),\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57be36ed-6972-4c5e-8fe6-d50204fa000e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 02:50:18.664583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 02:50:18.667397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 02:50:18.667616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 02:50:18.668617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 02:50:18.668929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 02:50:18.669161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 02:50:18.669328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 02:50:19.208333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 02:50:19.208539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 02:50:19.208698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 02:50:19.208839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1610 MB memory:  -> device: 0, name: NVIDIA GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300,300,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a637247-4678-47f5-8a5f-ebe90378cb89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc2de50-5d97-45a9-86d3-0a50fa79a07a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/learning-datasets/validation-horse-or-human.zip\"\n",
    "file_name = \"validation-horse-or-human.zip\"\n",
    "validation_dir = 'horse-or-human/validation/'\n",
    "urllib.request.urlretrieve(url, file_name)\n",
    "\n",
    "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
    "zip_ref.extractall(validation_dir)\n",
    "zip_ref.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d15049f-5ad3-4c0a-86fc-79e0a58eb0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da0d4ea3-6224-4dc6-bb71-5be088571b94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(300,300),\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a8dfb-1944-40a6-a740-25bb65afceb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fecdc00-5ff0-4229-bd8e-dbc68a595e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1a2dcf3-2d4a-43d6-93b2-eb80d9d21523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 02:50:21.943215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-02-14 02:50:24.163041: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1acd4150 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-14 02:50:24.163074: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce 940MX, Compute Capability 5.0\n",
      "2023-02-14 02:50:24.167563: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-14 02:50:24.273965: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 19s 377ms/step - loss: 0.6662 - accuracy: 0.6599 - val_loss: 0.5531 - val_accuracy: 0.7266\n",
      "Epoch 2/15\n",
      "33/33 [==============================] - 11s 338ms/step - loss: 0.4763 - accuracy: 0.8533 - val_loss: 0.6761 - val_accuracy: 0.8555\n",
      "Epoch 3/15\n",
      "33/33 [==============================] - 11s 338ms/step - loss: 0.3042 - accuracy: 0.9018 - val_loss: 0.5716 - val_accuracy: 0.8711\n",
      "Epoch 4/15\n",
      "33/33 [==============================] - 11s 338ms/step - loss: 0.1115 - accuracy: 0.9572 - val_loss: 1.4396 - val_accuracy: 0.8086\n",
      "Epoch 5/15\n",
      "33/33 [==============================] - 11s 338ms/step - loss: 0.3391 - accuracy: 0.9368 - val_loss: 1.0065 - val_accuracy: 0.8320\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - 11s 338ms/step - loss: 0.0833 - accuracy: 0.9738 - val_loss: 0.8497 - val_accuracy: 0.8398\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - 11s 338ms/step - loss: 0.0893 - accuracy: 0.9874 - val_loss: 2.0136 - val_accuracy: 0.7930\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - 11s 337ms/step - loss: 0.0571 - accuracy: 0.9845 - val_loss: 1.2185 - val_accuracy: 0.8555\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - 11s 338ms/step - loss: 0.1832 - accuracy: 0.9864 - val_loss: 1.6064 - val_accuracy: 0.8086\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - 11s 337ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 1.8035 - val_accuracy: 0.8438\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - 11s 338ms/step - loss: 0.0743 - accuracy: 0.9825 - val_loss: 1.5673 - val_accuracy: 0.8281\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - 11s 337ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0244 - val_accuracy: 0.8320\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - 11s 338ms/step - loss: 0.1749 - accuracy: 0.9767 - val_loss: 2.1824 - val_accuracy: 0.8281\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - 11s 337ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4810 - val_accuracy: 0.9062\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - 11s 338ms/step - loss: 3.2961e-04 - accuracy: 1.0000 - val_loss: 1.1639 - val_accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=15, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0921d37-7418-408b-b964-1583a8551854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('horse-human-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a533138-63b2-406a-9116-814766849b57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 149, 149, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "from  tensorflow.keras.models import load_model\n",
    "savedModel=load_model('horse-human-model.h5')\n",
    "savedModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a7a8429-9609-48a3-b113-6f72e1a4eb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f80406b14f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73375e-bc30-4939-bfe7-a085bac30a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3c54d-9db0-4c35-9725-a6a7c9bb6bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
